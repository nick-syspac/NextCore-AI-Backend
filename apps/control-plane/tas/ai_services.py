"""
AI Services for Training and Assessment Strategy (TAS) Module

Provides AI-powered capabilities for:
- Content generation and drafting
- Compliance checking and validation
- Entity extraction and normalization
- Assessment mapping and blueprinting
- Evidence summarization
- Policy analysis and recommendations
"""

import logging
import json
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
import hashlib

logger = logging.getLogger(__name__)


class AIServiceBase:
    """Base class for AI services with common utilities"""

    def __init__(self, model_name: str = "gpt-4o"):
        self.model_name = model_name
        self.temperature = 0.7
        self.max_tokens = 2000

    def _call_llm(self, prompt: str, system_message: str = None, **kwargs) -> str:
        """
        Call the LLM API with error handling

        Args:
            prompt: User prompt
            system_message: System context message
            **kwargs: Additional API parameters

        Returns:
            Generated text response
        """
        try:
            # TODO: Implement actual OpenAI API call
            # For now, return a placeholder
            logger.info(f"LLM call: {prompt[:100]}...")
            return "AI-generated response placeholder"
        except Exception as e:
            logger.error(f"LLM API error: {str(e)}")
            raise

    def _get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Get embeddings for texts using embedding model

        Args:
            texts: List of text strings to embed

        Returns:
            List of embedding vectors
        """
        try:
            # TODO: Implement actual embedding API call
            logger.info(f"Getting embeddings for {len(texts)} texts")
            return [[0.0] * 1536 for _ in texts]  # Placeholder
        except Exception as e:
            logger.error(f"Embedding API error: {str(e)}")
            raise

    def _extract_citations(self, text: str, sources: List[Dict]) -> List[Dict]:
        """
        Extract and link citations from generated text to source documents

        Args:
            text: Generated text
            sources: Source documents that were used

        Returns:
            List of citation objects with source references
        """
        citations = []
        for idx, source in enumerate(sources):
            # Simple citation detection (improve with better logic)
            if any(keyword in text.lower() for keyword in source.get("keywords", [])):
                citations.append(
                    {
                        "source_id": source.get("id"),
                        "source_type": source.get("type"),
                        "excerpt": source.get("text", "")[:200],
                        "relevance": 0.8,  # Placeholder score
                    }
                )
        return citations


class IntakePrefillService(AIServiceBase):
    """
    AI Service for intake and prefill operations

    Capabilities:
    - Entity extraction from policies, CVs, facilities
    - TGA snapshot enrichment
    - Cohort archetype suggestions
    """

    def extract_trainer_details(self, cv_text: str, pd_logs: List[Dict]) -> Dict:
        """
        Extract and normalize trainer information from CV and PD logs

        Args:
            cv_text: Trainer CV/resume text
            pd_logs: Professional development logs

        Returns:
            Structured trainer data
        """
        system_message = """You are an RTO compliance expert. Extract trainer qualifications, 
        industry experience, and vocational competency from the provided CV. 
        Format as structured JSON with TAE40116/TAE40110 compliance checks."""

        prompt = f"""Analyze this trainer CV and PD logs. Extract:
        1. Formal qualifications (with levels and years)
        2. Industry experience (roles, years, sectors)
        3. TAE qualification and currency
        4. Vocational competency evidence
        5. Missing compliance requirements
        
        CV:
        {cv_text[:2000]}
        
        PD Logs:
        {json.dumps(pd_logs[:5], indent=2)}
        
        Return structured JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            # TODO: Parse JSON response
            return {
                "qualifications": [],
                "industry_experience": [],
                "tae_status": "compliant",
                "missing_requirements": [],
                "vocational_competency_score": 0.85,
                "extracted_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Trainer extraction error: {e}")
            return {"error": str(e)}

    def enrich_tga_snapshot(self, unit_code: str, tga_data: Dict) -> Dict:
        """
        Enrich TGA unit data with trainer-friendly learning outcomes and assessment hints

        Args:
            unit_code: Unit of competency code
            tga_data: Raw TGA data with elements/PC/KS/FS

        Returns:
            Enriched unit data with learning outcomes and assessment hints
        """
        system_message = """You are a VET curriculum designer. Transform technical TGA 
        unit descriptors into practical learning outcomes and assessment guidance for trainers."""

        prompt = f"""Convert this TGA unit into trainer-friendly format:
        
        Unit: {unit_code}
        Title: {tga_data.get('title', '')}
        
        Elements and Performance Criteria:
        {json.dumps(tga_data.get('elements', [])[:3], indent=2)}
        
        Knowledge Evidence:
        {tga_data.get('knowledge_evidence', '')[:500]}
        
        Provide:
        1. 3-5 clear learning outcomes (what students will be able to do)
        2. Suggested assessment methods for each element
        3. Context/industry application examples
        4. Common evidence types
        5. Trainer delivery hints
        
        Return as structured JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "unit_code": unit_code,
                "learning_outcomes": [],
                "assessment_hints": [],
                "industry_contexts": [],
                "evidence_types": [],
                "delivery_notes": "",
                "enriched_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"TGA enrichment error: {e}")
            return {"error": str(e)}

    def suggest_cohort_archetype(
        self, cohort_history: List[Dict], demographics: Dict
    ) -> Dict:
        """
        Analyze cohort history and suggest learner profiles and reasonable adjustments

        Args:
            cohort_history: Historical cohort data (LLN, completions, withdrawals)
            demographics: Current cohort demographics

        Returns:
            Cohort archetype with support recommendations
        """
        system_message = """You are an RTO student support specialist. Analyze cohort 
        patterns to recommend targeted support strategies."""

        prompt = f"""Based on historical data, suggest cohort profile and support:
        
        Historical Completion Rate: {cohort_history[0].get('completion_rate', 0) if cohort_history else 0}%
        Average LLN Level: {cohort_history[0].get('avg_lln_level', 'N/A') if cohort_history else 'N/A'}
        Common Withdrawal Reasons: {cohort_history[0].get('withdrawal_reasons', []) if cohort_history else []}
        
        Current Cohort:
        Size: {demographics.get('size', 0)}
        Age Range: {demographics.get('age_range', '')}
        Background: {demographics.get('background', '')}
        
        Provide:
        1. Cohort archetype name and description
        2. LLN support intensity (low/medium/high)
        3. Recommended reasonable adjustments
        4. At-risk indicators to monitor
        5. Suggested support hours per week
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "archetype": "Mixed Adult Learners",
                "lln_support_level": "medium",
                "reasonable_adjustments": [],
                "risk_indicators": [],
                "support_hours_per_week": 2,
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Cohort archetype error: {e}")
            return {"error": str(e)}


class PackagingClusteringService(AIServiceBase):
    """
    AI Service for packaging, clustering, and timetabling

    Capabilities:
    - Elective recommendations based on job outcomes
    - Smart unit clustering by semantic similarity
    - Timetable optimization
    """

    def recommend_electives(
        self,
        qualification_code: str,
        job_outcomes: List[str],
        available_electives: List[Dict],
        packaging_rules: str,
    ) -> List[Dict]:
        """
        Recommend elective units based on job outcomes and packaging rules

        Args:
            qualification_code: Qualification code
            job_outcomes: Target job roles/outcomes
            available_electives: Available elective units
            packaging_rules: Packaging rule requirements

        Returns:
            Ranked list of recommended electives with rationale
        """
        system_message = """You are a VET pathway advisor. Recommend elective units that 
        best prepare learners for specific job outcomes while meeting packaging rules."""

        electives_summary = "\n".join(
            [f"- {e['code']}: {e['title']}" for e in available_electives[:20]]
        )

        prompt = f"""Recommend elective units for {qualification_code} targeting these jobs:
        {', '.join(job_outcomes)}
        
        Packaging Rules:
        {packaging_rules}
        
        Available Electives:
        {electives_summary}
        
        For each recommendation provide:
        1. Unit code and title
        2. Relevance score (0-1)
        3. Why it suits the job outcome
        4. Skill/competency it develops
        5. Industry demand indicator
        
        Return top 10 as JSON array."""

        try:
            response = self._call_llm(prompt, system_message)
            return [
                {
                    "unit_code": e["code"],
                    "title": e["title"],
                    "relevance_score": 0.9,
                    "rationale": "Aligns with job outcome",
                    "skills_developed": [],
                    "industry_demand": "high",
                }
                for e in available_electives[:5]
            ]
        except Exception as e:
            logger.error(f"Elective recommendation error: {e}")
            return []

    def suggest_unit_clusters(
        self, units: List[Dict], max_cluster_size: int = 4
    ) -> List[Dict]:
        """
        Suggest unit clusters based on semantic similarity and shared contexts

        Args:
            units: List of units with elements, PC, KS, FS
            max_cluster_size: Maximum units per cluster

        Returns:
            List of suggested clusters with rationale
        """
        # Get embeddings for unit descriptions
        unit_texts = [
            f"{u['code']} {u['title']} {u.get('application', '')}" for u in units
        ]
        embeddings = self._get_embeddings(unit_texts)

        # TODO: Implement clustering algorithm (k-means, hierarchical, etc.)

        system_message = """You are a VET curriculum designer. Analyze units and suggest 
        logical clustering that maximizes shared learning contexts and assessment opportunities."""

        prompt = f"""Suggest optimal unit clusters for delivery:
        
        Units:
        {json.dumps([{
            'code': u['code'], 
            'title': u['title'],
            'application': u.get('application', '')[:200]
        } for u in units], indent=2)}
        
        For each cluster provide:
        1. Cluster name (theme-based)
        2. Units in cluster (codes)
        3. Shared knowledge/skills
        4. Common industry contexts
        5. Integrated assessment opportunities
        6. Delivery sequence recommendation
        
        Return as JSON array."""

        try:
            response = self._call_llm(prompt, system_message)
            return [
                {
                    "cluster_name": "Foundation Skills",
                    "units": [u["code"] for u in units[:max_cluster_size]],
                    "shared_elements": [],
                    "contexts": [],
                    "assessment_opportunities": [],
                    "sequence": "parallel",
                    "rationale": "Common foundational knowledge",
                }
            ]
        except Exception as e:
            logger.error(f"Clustering error: {e}")
            return []

    def optimize_timetable(
        self, clusters: List[Dict], total_weeks: int, resources: Dict, constraints: Dict
    ) -> Dict:
        """
        Optimize timetable allocation across weeks

        Args:
            clusters: Unit clusters with hour requirements
            total_weeks: Total delivery weeks
            resources: Available resources (rooms, trainers, equipment)
            constraints: Delivery constraints (trainer availability, room capacity)

        Returns:
            Optimized timetable with resource allocation
        """
        system_message = """You are a VET timetable planner. Create optimal schedules 
        that minimize resource conflicts and maintain appropriate pacing."""

        prompt = f"""Create a {total_weeks}-week timetable:
        
        Clusters:
        {json.dumps(clusters, indent=2)[:1000]}
        
        Resources:
        Rooms: {resources.get('rooms', [])}
        Trainers: {resources.get('trainer_count', 0)}
        
        Constraints:
        {json.dumps(constraints, indent=2)}
        
        Provide:
        1. Week-by-week allocation
        2. Contact hours per week per cluster
        3. Resource assignments (room, trainer)
        4. Conflict warnings
        5. Pacing notes (too dense/sparse weeks)
        
        Return as structured JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "weeks": [],
                "resource_utilization": {},
                "conflicts": [],
                "recommendations": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Timetable optimization error: {e}")
            return {"error": str(e)}


class TASContentDrafter(AIServiceBase):
    """
    AI Service for drafting TAS content

    Capabilities:
    - Contextual copy generation for TAS sections
    - Assessment blueprinting
    - Resource mapping
    """

    def draft_cohort_needs_section(
        self, cohort_data: Dict, qualification: str, delivery_context: str
    ) -> Dict:
        """
        Generate cohort needs analysis section

        Args:
            cohort_data: Cohort demographics and characteristics
            qualification: Qualification code and title
            delivery_context: Delivery setting and mode

        Returns:
            Drafted section with justification and citations
        """
        system_message = """You are an RTO compliance writer. Draft cohort needs sections 
        that demonstrate understanding of learner characteristics and appropriate support strategies.
        Always provide evidence-based justification."""

        prompt = f"""Draft a cohort needs analysis for:
        
        Qualification: {qualification}
        Cohort Size: {cohort_data.get('size', 0)}
        Demographics: {cohort_data.get('demographics', {})}
        LLN Levels: {cohort_data.get('lln_assessment', '')}
        Previous Education: {cohort_data.get('education_background', '')}
        Employment Status: {cohort_data.get('employment_status', '')}
        Delivery Context: {delivery_context}
        
        Include:
        1. Cohort profile summary (2-3 paragraphs)
        2. Learning support needs identification
        3. LLN support strategies
        4. Reasonable adjustments considerations
        5. Engagement strategies
        
        Each point must have "because..." justification linked to cohort data.
        
        Return as JSON with 'content', 'justifications', and 'asqa_clauses' fields."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.6)
            return {
                "content": "Drafted cohort needs content",
                "justifications": [],
                "asqa_clauses_addressed": ["1.1", "1.2"],
                "word_count": 0,
                "citations": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Content drafting error: {e}")
            return {"error": str(e)}

    def generate_assessment_blueprint(
        self,
        unit_code: str,
        elements: List[Dict],
        delivery_mode: str,
        industry_context: str,
    ) -> Dict:
        """
        Generate assessment blueprint mapping elements/PC to tasks and instruments

        Args:
            unit_code: Unit of competency code
            elements: Unit elements with performance criteria
            delivery_mode: classroom/workplace/online/blended
            industry_context: Industry setting for assessments

        Returns:
            Assessment blueprint with tasks, instruments, and rubrics
        """
        system_message = """You are a VET assessment specialist. Design assessment 
        blueprints that comprehensively cover all elements and PC with valid, reliable 
        instruments. Ensure authenticity and industry relevance."""

        prompt = f"""Create assessment blueprint for {unit_code}:
        
        Elements & Performance Criteria:
        {json.dumps(elements, indent=2)[:2000]}
        
        Delivery Mode: {delivery_mode}
        Industry Context: {industry_context}
        
        For each element, design:
        1. Assessment task overview
        2. Instrument type (practical demo, project, written, observation, etc.)
        3. Specific PC being assessed
        4. Evidence to be collected
        5. Assessment context/scenario
        6. Rubric criteria outline
        7. Timing and duration
        
        Return comprehensive JSON structure."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.5)
            return {
                "unit_code": unit_code,
                "assessment_tasks": [],
                "instruments": [],
                "rubric_skeletons": [],
                "observation_checklists": [],
                "coverage_matrix": {},
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Assessment blueprint error: {e}")
            return {"error": str(e)}

    def map_resources(
        self,
        unit_requirements: Dict,
        available_inventory: List[Dict],
        budget_constraints: Dict,
    ) -> Dict:
        """
        Map unit resource requirements to available inventory and suggest substitutes

        Args:
            unit_requirements: Required resources from TGA
            available_inventory: Current facility inventory
            budget_constraints: Budget limits for new resources

        Returns:
            Resource mapping with gaps and mitigation suggestions
        """
        system_message = """You are an RTO resource planner. Match unit requirements 
        to available resources and suggest practical alternatives or mitigation strategies."""

        prompt = f"""Map resources for unit:
        
        Required Resources:
        {json.dumps(unit_requirements, indent=2)}
        
        Available Inventory:
        {json.dumps(available_inventory[:20], indent=2)}
        
        Budget: ${budget_constraints.get('max_per_unit', 0)}
        
        Provide:
        1. Direct matches (requirement â†’ inventory item)
        2. Substitute options (with adequacy justification)
        3. Gaps that need purchase (with cost estimates)
        4. Simulation/alternative delivery options
        5. Third-party access arrangements
        6. Mitigation text for TAS (if gaps exist)
        
        Return structured JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "direct_matches": [],
                "substitutes": [],
                "gaps": [],
                "mitigation_strategies": [],
                "estimated_cost": 0,
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Resource mapping error: {e}")
            return {"error": str(e)}


class ComplianceRAGService(AIServiceBase):
    """
    AI Service for compliance checking with Retrieval-Augmented Generation

    Capabilities:
    - ASQA clause coverage evaluation
    - Trainer suitability scoring
    - Facility adequacy assessment
    - Policy drift detection
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.asqa_standards = self._load_asqa_standards()
        self.policies_index = self._build_policies_index()

    def _load_asqa_standards(self) -> Dict:
        """
        Load ASQA Standards for RTOs 2025
        
        Note: The 2025 Standards introduced an outcome-focused framework with:
        - 4 Quality Areas (Outcome Standards)
        - Compliance Requirements
        - Credential Policy
        
        This method should be updated to load from the database ASQAStandard model
        which now supports both 2015 (legacy) and 2025 standards structures.
        """
        # TODO: Load from database ASQAStandard model (version='2025')
        # For now, return basic structure matching 2025 standards
        return {
            "QA1.1": "Training is delivered in accordance with the requirements of training products...",
            "QA1.2": "Assessment is conducted in accordance with the principles of assessment and rules of evidence...",
            "QA1.3": "RTOs acknowledge and give credit for skills and knowledge learners already have...",
            "QA1.4": "Training and assessment is delivered with appropriate facilities, resources and equipment...",
            "QA2.1": "Learners are provided with accurate and accessible information...",
            "QA2.2": "Learners receive appropriate training support to achieve their learning outcomes...",
            "QA3.1": "The VET workforce is appropriately qualified, inducted, supported and developed...",
            "QA3.2": "Trainers and assessors hold required credentials and maintain vocational competence...",
            "QA4.1": "Effective governance and leadership drive quality training outcomes...",
            "QA4.2": "Risks to quality training outcomes are identified and effectively managed...",
            "QA4.3": "Systematic monitoring and evaluation drive continuous improvement...",
        }

    def _build_policies_index(self) -> Dict:
        """Build searchable index of RTO policies"""
        # TODO: Implement vector search index
        return {}

    def evaluate_clause_coverage(
        self, tas_content: Dict, target_clauses: List[str] = None
    ) -> Dict:
        """
        Evaluate whether TAS content adequately addresses ASQA clauses

        Args:
            tas_content: TAS document sections
            target_clauses: Specific clauses to check (or all if None)
                           Updated for 2025 Standards (QA1.1, QA1.2, etc.)

        Returns:
            Clause coverage report with gaps and suggested fixes
        """
        if target_clauses is None:
            # Default to key 2025 Outcome Standards relevant to TAS
            target_clauses = [
                "QA1.1",  # Training
                "QA1.2",  # Assessment
                "QA1.3",  # RPL & Credit Transfer
                "QA1.4",  # Facilities & Resources
                "QA2.1",  # Information
                "QA2.2",  # Training Support
                "QA3.2",  # Trainer & Assessor Credentials
                "QA4.3",  # Continuous Improvement
            ]

        results = {}
        for clause in target_clauses:
            standard_text = self.asqa_standards.get(clause, "")

            system_message = f"""You are an ASQA auditor. Evaluate if the TAS content 
            adequately addresses Standard {clause}. Be specific about what's present, 
            what's missing, and what needs improvement."""

            prompt = f"""Evaluate clause {clause} coverage:
            
            Standard {clause}:
            {standard_text}
            
            TAS Content:
            {json.dumps(tas_content, indent=2)[:2000]}
            
            Assess:
            1. Coverage status (compliant/partial/non-compliant)
            2. What requirements are addressed
            3. What requirements are missing
            4. Specific evidence gaps
            5. Suggested additions/fixes
            6. Risk level if left unaddressed
            
            Return as JSON."""

            try:
                response = self._call_llm(prompt, system_message, temperature=0.3)
                results[clause] = {
                    "status": "partial",
                    "addressed": [],
                    "missing": [],
                    "evidence_gaps": [],
                    "suggested_fixes": [],
                    "risk_level": "medium",
                    "generated_at": datetime.utcnow().isoformat(),
                }
            except Exception as e:
                logger.error(f"Clause evaluation error for {clause}: {e}")
                results[clause] = {"error": str(e)}

        return {
            "overall_status": "partial",
            "clause_results": results,
            "priority_fixes": [],
            "evaluated_at": datetime.utcnow().isoformat(),
        }

    def score_trainer_suitability(
        self, trainer_profile: Dict, unit_requirements: Dict
    ) -> Dict:
        """
        Score trainer suitability for delivering a unit

        Args:
            trainer_profile: Trainer quals, experience, currency
            unit_requirements: Unit requirements for trainer/assessor

        Returns:
            Suitability score with gap analysis and PD recommendations
        """
        system_message = """You are an RTO compliance officer. Assess trainer suitability 
        against TAE40116/TAE40110 and vocational competency requirements. Be objective."""

        prompt = f"""Assess trainer suitability:
        
        Trainer Profile:
        Qualifications: {trainer_profile.get('qualifications', [])}
        TAE Status: {trainer_profile.get('tae_status', '')}
        Industry Experience: {trainer_profile.get('industry_experience', [])}
        Currency Evidence: {trainer_profile.get('currency_evidence', [])}
        
        Unit Requirements:
        {json.dumps(unit_requirements, indent=2)}
        
        Provide:
        1. Overall suitability score (0-100)
        2. TAE compliance (yes/no/needs update)
        3. Vocational competency assessment (adequate/gap)
        4. Currency status (current/needs refresh)
        5. Specific gaps or missing evidence
        6. PD recommendations with priorities
        7. Risk level if trainer proceeds without remediation
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.3)
            return {
                "suitability_score": 75,
                "tae_compliant": True,
                "vocational_competency": "adequate",
                "currency_status": "current",
                "gaps": [],
                "pd_recommendations": [],
                "risk_level": "low",
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Trainer scoring error: {e}")
            return {"error": str(e)}

    def assess_facility_adequacy(
        self, facility_inventory: List[Dict], unit_requirements: Dict
    ) -> Dict:
        """
        Assess facility adequacy for unit delivery

        Args:
            facility_inventory: Available facilities, equipment, software
            unit_requirements: Unit resource requirements

        Returns:
            Adequacy assessment with mitigation suggestions
        """
        system_message = """You are an RTO facilities auditor. Assess if facilities 
        meet unit requirements. Suggest practical mitigation for any gaps."""

        prompt = f"""Assess facility adequacy:
        
        Available Facilities:
        {json.dumps(facility_inventory, indent=2)[:1500]}
        
        Unit Requirements:
        {json.dumps(unit_requirements, indent=2)}
        
        Evaluate:
        1. Adequacy status (adequate/partial/inadequate)
        2. What requirements are met
        3. What gaps exist
        4. Safety/compliance issues
        5. Mitigation options (simulation, third-party, modification)
        6. Mitigation text for TAS
        7. Capital expenditure needs
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "adequacy_status": "adequate",
                "requirements_met": [],
                "gaps": [],
                "safety_issues": [],
                "mitigation_options": [],
                "mitigation_text": "",
                "capex_needed": 0,
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Facility assessment error: {e}")
            return {"error": str(e)}

    def detect_policy_drift(
        self, tas_policy_references: List[Dict], current_policies: List[Dict]
    ) -> Dict:
        """
        Detect when referenced policies have changed since TAS approval

        Args:
            tas_policy_references: Policies referenced in TAS with versions
            current_policies: Current policy versions

        Returns:
            Drift report with suggested TAS updates
        """
        drifts = []

        for tas_ref in tas_policy_references:
            policy_name = tas_ref.get("name")
            tas_version = tas_ref.get("version")

            # Find current policy
            current = next(
                (p for p in current_policies if p.get("name") == policy_name), None
            )

            if current and current.get("version") != tas_version:
                system_message = """You are an RTO policy analyst. Explain policy changes 
                and suggest how TAS should be updated to remain compliant."""

                prompt = f"""Policy has changed:
                
                Policy: {policy_name}
                TAS Referenced Version: {tas_version}
                Current Version: {current.get('version')}
                
                Key Changes:
                {current.get('change_summary', '')}
                
                TAS Text Affected:
                {tas_ref.get('tas_text', '')}
                
                Suggest:
                1. Impact on TAS (high/medium/low)
                2. What TAS sections need updating
                3. Proposed new wording
                4. Compliance risk if not updated
                
                Return as JSON."""

                try:
                    response = self._call_llm(prompt, system_message)
                    drifts.append(
                        {
                            "policy_name": policy_name,
                            "old_version": tas_version,
                            "new_version": current.get("version"),
                            "impact": "medium",
                            "affected_sections": [],
                            "proposed_updates": "",
                            "risk": "medium",
                        }
                    )
                except Exception as e:
                    logger.error(f"Policy drift analysis error: {e}")

        return {
            "drifts_detected": len(drifts),
            "drifts": drifts,
            "high_priority_count": len(
                [d for d in drifts if d.get("impact") == "high"]
            ),
            "checked_at": datetime.utcnow().isoformat(),
        }


class EvidenceService(AIServiceBase):
    """
    AI Service for evidence pack generation and audit readiness

    Capabilities:
    - Minutes summarization
    - Validation/moderation planning
    - Snapshot difference explanation
    """

    def summarize_industry_minutes(
        self, minutes_text: str, meeting_date: str, attendees: List[str]
    ) -> Dict:
        """
        Summarize industry engagement minutes into compliant evidence entries

        Args:
            minutes_text: Raw meeting minutes
            meeting_date: Date of meeting
            attendees: List of attendees

        Returns:
            Structured evidence entry with outcomes and TAS linkages
        """
        system_message = """You are an RTO evidence curator. Extract key outcomes, 
        industry feedback, and TAS implications from industry engagement minutes. 
        Format for audit purposes."""

        prompt = f"""Summarize industry engagement minutes:
        
        Date: {meeting_date}
        Attendees: {', '.join(attendees)}
        
        Minutes:
        {minutes_text[:3000]}
        
        Extract:
        1. Key discussion points (3-5 bullet points)
        2. Industry feedback on qualification/units
        3. Suggested changes to TAS
        4. Skills gaps identified
        5. Employment opportunities discussed
        6. Actions agreed upon
        7. Evidence of industry currency
        
        Link each point to specific TAS sections that should be updated.
        
        Return as structured JSON."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.4)
            return {
                "meeting_date": meeting_date,
                "summary": "",
                "key_points": [],
                "tas_implications": [],
                "actions": [],
                "evidence_quality": "high",
                "tas_sections_to_update": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Minutes summarization error: {e}")
            return {"error": str(e)}

    def generate_validation_plan(
        self,
        assessment_tasks: List[Dict],
        cohort_size: int,
        last_validation_date: Optional[str] = None,
    ) -> Dict:
        """
        Generate rolling validation matrix for assessments

        Args:
            assessment_tasks: List of assessment tasks
            cohort_size: Expected cohort size
            last_validation_date: Date of last validation

        Returns:
            Validation plan with schedule, samples, and responsibilities
        """
        system_message = """You are an RTO validation coordinator. Design practical 
        validation plans that meet Standard 1.8 requirements. Consider workload distribution."""

        prompt = f"""Create validation plan:
        
        Assessment Tasks:
        {json.dumps([{
            'unit': t.get('unit_code'),
            'task': t.get('name'),
            'type': t.get('instrument_type')
        } for t in assessment_tasks], indent=2)}
        
        Cohort Size: {cohort_size}
        Last Validation: {last_validation_date or 'Never'}
        
        Design:
        1. Rolling validation schedule (12 months)
        2. Sample sizes per task (10% minimum)
        3. Validator assignments (internal/external mix)
        4. Meeting/moderation schedule
        5. Records to maintain
        6. Email templates for validator invitations
        7. Risk prioritization (high-stakes assessments first)
        
        Return as structured JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "schedule": [],
                "sample_requirements": {},
                "validator_assignments": [],
                "meeting_dates": [],
                "documentation_requirements": [],
                "email_templates": {},
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Validation planning error: {e}")
            return {"error": str(e)}

    def explain_version_differences(self, old_version: Dict, new_version: Dict) -> Dict:
        """
        Generate plain-English explanation of changes between TAS versions

        Args:
            old_version: Previous TAS version
            new_version: Current TAS version

        Returns:
            Change explanation with rationale draft
        """
        # Calculate structural diff
        changes = self._calculate_diff(old_version, new_version)

        system_message = """You are an RTO documentation officer. Explain TAS changes 
        in clear language suitable for auditors and approvers. Focus on WHY changes 
        were made, not just WHAT changed."""

        prompt = f"""Explain TAS version changes:
        
        Changes Detected:
        {json.dumps(changes, indent=2)[:2000]}
        
        For each change provide:
        1. Plain English description
        2. Reason for change (compliance/quality/feedback)
        3. Impact on delivery
        4. Impact on assessment
        5. Related policy/standard
        6. Approval rationale
        
        Return as structured JSON."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.5)
            return {
                "summary": "",
                "changes": [],
                "rationale_draft": "",
                "impact_analysis": {},
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Version diff explanation error: {e}")
            return {"error": str(e)}

    def _calculate_diff(self, old: Dict, new: Dict) -> List[Dict]:
        """Calculate structural differences between versions"""
        changes = []

        # Simple field-level diff (improve with deep comparison)
        for key in set(list(old.keys()) + list(new.keys())):
            old_val = old.get(key)
            new_val = new.get(key)

            if old_val != new_val:
                changes.append(
                    {
                        "field": key,
                        "old_value": str(old_val)[:100] if old_val else None,
                        "new_value": str(new_val)[:100] if new_val else None,
                        "change_type": (
                            "modified"
                            if old_val and new_val
                            else ("added" if new_val else "removed")
                        ),
                    }
                )

        return changes


class QualityAnalyticsService(AIServiceBase):
    """
    AI Service for quality and risk analytics

    Capabilities:
    - LLN risk prediction
    - Completion/withdrawal risk analysis
    - Consistency checking across systems
    """

    def predict_lln_risk(
        self, cohort_data: Dict, historical_cohorts: List[Dict]
    ) -> Dict:
        """
        Predict LLN support intensity based on cohort characteristics and history

        Args:
            cohort_data: Current cohort demographics and assessments
            historical_cohorts: Historical cohort performance data

        Returns:
            LLN risk prediction with support recommendations
        """
        # Simple ML model placeholder (implement proper ML pipeline)
        avg_lln_score = cohort_data.get("avg_lln_score", 3)
        risk_level = (
            "low"
            if avg_lln_score >= 3
            else ("medium" if avg_lln_score >= 2 else "high")
        )

        system_message = """You are an RTO student support analyst. Predict LLN support 
        needs and recommend specific interventions."""

        prompt = f"""Predict LLN support requirements:
        
        Current Cohort:
        Average LLN Score: {avg_lln_score}/5
        Demographics: {cohort_data.get('demographics', {})}
        Background: {cohort_data.get('background', '')}
        
        Historical Data:
        {json.dumps(historical_cohorts[:3], indent=2)}
        
        Predict:
        1. Risk level (low/medium/high)
        2. Required support hours per week
        3. Specific interventions (workshops, 1-on-1, resources)
        4. At-risk student count estimate
        5. Budget estimate for support
        6. Success probability with/without support
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "risk_level": risk_level,
                "support_hours_per_week": 2,
                "interventions": [],
                "at_risk_count": 0,
                "budget_estimate": 0,
                "success_probability": {"with_support": 0.85, "without_support": 0.65},
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"LLN risk prediction error: {e}")
            return {"error": str(e)}

    def analyze_completion_risk(
        self, clusters: List[Dict], delivery_schedule: Dict
    ) -> Dict:
        """
        Analyze risk of non-completion based on clustering and schedule density

        Args:
            clusters: Unit clusters
            delivery_schedule: Week-by-week delivery plan

        Returns:
            Risk analysis with re-sequencing suggestions
        """
        system_message = """You are a VET delivery analyst. Identify scheduling patterns 
        that historically correlate with withdrawals or non-completions."""

        prompt = f"""Analyze completion risk:
        
        Clusters:
        {json.dumps(clusters, indent=2)[:1500]}
        
        Schedule:
        {json.dumps(delivery_schedule, indent=2)[:1500]}
        
        Assess:
        1. High-risk periods (assessment overload, density issues)
        2. Prerequisite violations (units out of order)
        3. Pacing problems (too fast/slow)
        4. Resource contention issues
        5. Re-sequencing recommendations
        6. Alternative scheduling options
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message)
            return {
                "overall_risk": "medium",
                "high_risk_periods": [],
                "prerequisite_issues": [],
                "pacing_analysis": {},
                "recommendations": [],
                "alternative_schedules": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Completion risk analysis error: {e}")
            return {"error": str(e)}

    def check_system_consistency(
        self, tas_data: Dict, lms_data: Dict, assessment_tools: List[Dict]
    ) -> Dict:
        """
        Cross-validate consistency across TAS, LMS, and assessment tools

        Args:
            tas_data: TAS document data
            lms_data: LMS course structure
            assessment_tools: Assessment tool metadata

        Returns:
            Consistency report with discrepancies
        """
        discrepancies = []

        # Check unit codes
        tas_units = set(tas_data.get("units", []))
        lms_units = set(lms_data.get("units", []))

        if tas_units != lms_units:
            discrepancies.append(
                {
                    "type": "unit_mismatch",
                    "severity": "high",
                    "tas_value": list(tas_units),
                    "lms_value": list(lms_units),
                    "recommendation": "Sync unit codes between TAS and LMS",
                }
            )

        # Check assessment nomenclature
        # ... more checks

        return {
            "consistent": len(discrepancies) == 0,
            "discrepancies": discrepancies,
            "high_priority_count": len(
                [d for d in discrepancies if d.get("severity") == "high"]
            ),
            "checked_at": datetime.utcnow().isoformat(),
        }


class ConversationalCopilot(AIServiceBase):
    """
    AI Conversational Co-pilot for inline assistance

    Capabilities:
    - Contextual Q&A
    - Inline content generation
    - Guided prompts for audit-friendly text
    """

    def answer_inline_question(self, question: str, context: Dict) -> Dict:
        """
        Answer contextual question about TAS or compliance

        Args:
            question: User's question
            context: Current TAS context (section, unit, etc.)

        Returns:
            Answer with citations and related guidance
        """
        system_message = """You are an RTO compliance assistant. Answer questions about 
        TAS development, ASQA requirements, and best practices. Always cite specific 
        standards or guidelines."""

        prompt = f"""Question: {question}
        
        Context:
        Section: {context.get('section', '')}
        Unit: {context.get('unit', '')}
        Qualification: {context.get('qualification', '')}
        
        Current Content:
        {context.get('current_text', '')[:500]}
        
        Provide:
        1. Direct answer to question
        2. Relevant ASQA clause(s)
        3. Best practice guidance
        4. Example text if applicable
        5. Related resources/templates
        
        Return as JSON."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.6)
            return {
                "answer": "",
                "asqa_clauses": [],
                "best_practices": [],
                "example_text": "",
                "resources": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Inline question error: {e}")
            return {"error": str(e)}

    def generate_guided_content(self, prompt_template: str, context_vars: Dict) -> Dict:
        """
        Generate content using guided prompt template

        Args:
            prompt_template: Template with placeholders
            context_vars: Variables to fill template

        Returns:
            Generated audit-friendly content
        """
        filled_prompt = prompt_template.format(**context_vars)

        system_message = """You are an RTO compliance writer. Generate audit-friendly 
        content that is specific, evidence-based, and compliant with ASQA requirements. 
        Avoid generic statements."""

        prompt = f"""Generate content:
        
        {filled_prompt}
        
        Requirements:
        - Be specific and concrete
        - Reference actual data/evidence
        - Align with ASQA Standards
        - Use professional RTO language
        - Include "because..." justifications
        
        Return as JSON with 'content', 'word_count', 'asqa_alignment'."""

        try:
            response = self._call_llm(prompt, system_message, temperature=0.6)
            return {
                "content": "",
                "word_count": 0,
                "asqa_alignment": [],
                "generated_at": datetime.utcnow().isoformat(),
            }
        except Exception as e:
            logger.error(f"Guided content generation error: {e}")
            return {"error": str(e)}


# Service factory
class AIServiceFactory:
    """Factory for creating AI service instances"""

    @staticmethod
    def get_service(service_name: str, **kwargs) -> AIServiceBase:
        """Get AI service instance by name"""
        services = {
            "intake_prefill": IntakePrefillService,
            "packaging_clustering": PackagingClusteringService,
            "content_drafter": TASContentDrafter,
            "compliance_rag": ComplianceRAGService,
            "evidence": EvidenceService,
            "quality_analytics": QualityAnalyticsService,
            "copilot": ConversationalCopilot,
        }

        service_class = services.get(service_name)
        if not service_class:
            raise ValueError(f"Unknown service: {service_name}")

        return service_class(**kwargs)
