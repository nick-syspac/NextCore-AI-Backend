# Generated by Django 5.1.2 on 2025-10-24 01:21

import django.core.validators
import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('tenants', '0003_tenantapikey_description'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='Assessment',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('assessment_number', models.CharField(editable=False, max_length=50, unique=True)),
                ('unit_code', models.CharField(help_text='Training package unit code (e.g., BSBWHS211)', max_length=50)),
                ('unit_title', models.CharField(max_length=300)),
                ('training_package', models.CharField(blank=True, help_text='e.g., BSB - Business Services', max_length=100)),
                ('unit_release', models.CharField(blank=True, help_text='Release number', max_length=20)),
                ('assessment_type', models.CharField(choices=[('knowledge', 'Knowledge Assessment'), ('practical', 'Practical Assessment'), ('project', 'Project Assessment'), ('portfolio', 'Portfolio Assessment'), ('observation', 'Observation Checklist'), ('case_study', 'Case Study'), ('simulation', 'Simulation/Role Play'), ('integrated', 'Integrated Assessment'), ('written', 'Written Assessment'), ('oral', 'Oral Assessment')], max_length=20)),
                ('title', models.CharField(max_length=300)),
                ('version', models.CharField(default='1.0', max_length=20)),
                ('instructions', models.TextField(blank=True, help_text='AI-generated assessment instructions')),
                ('context', models.TextField(blank=True, help_text='Assessment context and scenario')),
                ('conditions', models.TextField(blank=True, help_text='Assessment conditions (equipment, resources, etc.)')),
                ('ai_generated', models.BooleanField(default=False)),
                ('ai_model', models.CharField(blank=True, help_text='e.g., GPT-4', max_length=50)),
                ('ai_prompt', models.TextField(blank=True, help_text='Prompt used for generation')),
                ('ai_generation_time', models.FloatField(blank=True, help_text='Generation time in seconds', null=True)),
                ('ai_generated_at', models.DateTimeField(blank=True, null=True)),
                ('blooms_analysis', models.JSONField(blank=True, default=dict, help_text="Bloom's taxonomy verb analysis: {level: count}")),
                ('blooms_distribution', models.JSONField(blank=True, default=dict, help_text="Distribution percentages across Bloom's levels")),
                ('dominant_blooms_level', models.CharField(blank=True, help_text="Most prominent Bloom's level", max_length=20)),
                ('is_compliant', models.BooleanField(default=False)),
                ('compliance_score', models.IntegerField(default=0, help_text='Overall compliance score (0-100)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(100)])),
                ('compliance_notes', models.TextField(blank=True)),
                ('elements_covered', models.JSONField(blank=True, default=list, help_text='List of unit elements covered')),
                ('performance_criteria_covered', models.JSONField(blank=True, default=list, help_text='List of performance criteria covered')),
                ('knowledge_evidence_covered', models.JSONField(blank=True, default=list, help_text='List of knowledge evidence items covered')),
                ('performance_evidence_covered', models.JSONField(blank=True, default=list, help_text='List of performance evidence items covered')),
                ('estimated_duration_hours', models.DecimalField(blank=True, decimal_places=2, help_text='Estimated completion time in hours', max_digits=5, null=True)),
                ('status', models.CharField(choices=[('draft', 'Draft'), ('generating', 'Generating with AI'), ('review', 'Under Review'), ('approved', 'Approved'), ('published', 'Published'), ('archived', 'Archived')], default='draft', max_length=20)),
                ('reviewed_at', models.DateTimeField(blank=True, null=True)),
                ('approved_at', models.DateTimeField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('approved_by', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='approved_assessments', to=settings.AUTH_USER_MODEL)),
                ('created_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='created_assessments', to=settings.AUTH_USER_MODEL)),
                ('reviewed_by', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='reviewed_assessments', to=settings.AUTH_USER_MODEL)),
                ('tenant', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='assessments', to='tenants.tenant')),
            ],
            options={
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='AssessmentGenerationLog',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('action', models.CharField(choices=[('generate_full', 'Full Assessment Generated'), ('generate_task', 'Task Generated'), ('generate_criteria', 'Criteria Generated'), ('analyze_blooms', "Bloom's Analysis Performed"), ('regenerate', 'Content Regenerated')], max_length=30)),
                ('ai_model', models.CharField(max_length=50)),
                ('prompt_used', models.TextField()),
                ('response_text', models.TextField(blank=True)),
                ('tokens_used', models.IntegerField(blank=True, null=True)),
                ('generation_time', models.FloatField(help_text='Time in seconds')),
                ('success', models.BooleanField(default=True)),
                ('error_message', models.TextField(blank=True)),
                ('performed_at', models.DateTimeField(auto_now_add=True)),
                ('assessment', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='generation_logs', to='assessment_builder.assessment')),
                ('performed_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'ordering': ['-performed_at'],
            },
        ),
        migrations.CreateModel(
            name='AssessmentTask',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('task_number', models.CharField(help_text="e.g., '1', '1a', 'A.1'", max_length=20)),
                ('task_type', models.CharField(choices=[('multiple_choice', 'Multiple Choice'), ('short_answer', 'Short Answer'), ('long_answer', 'Long Answer/Essay'), ('case_study', 'Case Study'), ('practical', 'Practical Demonstration'), ('project', 'Project Task'), ('portfolio', 'Portfolio Item'), ('observation', 'Observation'), ('presentation', 'Presentation'), ('role_play', 'Role Play/Simulation')], max_length=20)),
                ('question', models.TextField(help_text='The task question or instruction')),
                ('context', models.TextField(blank=True, help_text='Additional context, scenario, or information for the task')),
                ('ai_generated', models.BooleanField(default=False)),
                ('ai_rationale', models.TextField(blank=True, help_text='AI explanation of why this task was generated')),
                ('blooms_level', models.CharField(blank=True, help_text="Primary Bloom's taxonomy level", max_length=20)),
                ('blooms_verbs', models.JSONField(blank=True, default=list, help_text="Bloom's taxonomy verbs detected in this task")),
                ('maps_to_elements', models.JSONField(blank=True, default=list, help_text='Unit elements this task addresses')),
                ('maps_to_performance_criteria', models.JSONField(blank=True, default=list, help_text='Performance criteria this task addresses')),
                ('maps_to_knowledge_evidence', models.JSONField(blank=True, default=list, help_text='Knowledge evidence this task addresses')),
                ('question_count', models.IntegerField(default=1, help_text='Number of sub-questions (for multi-part tasks)')),
                ('estimated_time_minutes', models.IntegerField(blank=True, help_text='Estimated completion time in minutes', null=True)),
                ('marks_available', models.IntegerField(blank=True, help_text='Total marks for this task', null=True)),
                ('display_order', models.IntegerField(default=0)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('assessment', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='tasks', to='assessment_builder.assessment')),
            ],
            options={
                'ordering': ['assessment', 'display_order', 'task_number'],
            },
        ),
        migrations.CreateModel(
            name='AssessmentCriteria',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('criterion_number', models.CharField(max_length=20)),
                ('criterion_text', models.TextField(help_text='What the student must demonstrate')),
                ('unit_element', models.CharField(blank=True, max_length=100)),
                ('performance_criterion', models.CharField(blank=True, max_length=100)),
                ('knowledge_evidence', models.CharField(blank=True, max_length=100)),
                ('satisfactory_evidence', models.TextField(blank=True, help_text='What constitutes satisfactory performance')),
                ('not_satisfactory_evidence', models.TextField(blank=True, help_text='What would be unsatisfactory')),
                ('ai_generated', models.BooleanField(default=False)),
                ('display_order', models.IntegerField(default=0)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('assessment', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='criteria', to='assessment_builder.assessment')),
                ('task', models.ForeignKey(blank=True, help_text='Optional: Link to specific task', null=True, on_delete=django.db.models.deletion.CASCADE, related_name='criteria', to='assessment_builder.assessmenttask')),
            ],
            options={
                'verbose_name_plural': 'Assessment Criteria',
                'ordering': ['assessment', 'display_order', 'criterion_number'],
            },
        ),
        migrations.AddIndex(
            model_name='assessment',
            index=models.Index(fields=['tenant', 'status'], name='assessment__tenant__7edc48_idx'),
        ),
        migrations.AddIndex(
            model_name='assessment',
            index=models.Index(fields=['unit_code'], name='assessment__unit_co_f8f65a_idx'),
        ),
        migrations.AddIndex(
            model_name='assessment',
            index=models.Index(fields=['assessment_type'], name='assessment__assessm_d4a8d3_idx'),
        ),
        migrations.AddIndex(
            model_name='assessment',
            index=models.Index(fields=['created_at'], name='assessment__created_5008ba_idx'),
        ),
        migrations.AddIndex(
            model_name='assessmentgenerationlog',
            index=models.Index(fields=['assessment', 'performed_at'], name='assessment__assessm_90f9fc_idx'),
        ),
        migrations.AddIndex(
            model_name='assessmenttask',
            index=models.Index(fields=['assessment', 'display_order'], name='assessment__assessm_936243_idx'),
        ),
    ]
